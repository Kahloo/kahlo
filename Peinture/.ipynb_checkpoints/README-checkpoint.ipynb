{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"background:#FFFFAA\">\n",
    "<img src=\"logo.jpg\", width=150, ALIGN=\"left\", border=20>\n",
    "<center>\n",
    "<h1>Sample Starting Kit </h1>\n",
    " <br>This code was tested with <br>\n",
    "Python 3.6.6 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:07:29) (https://anaconda.org/)<br>\n",
    "<i> Adapted for Chalab by Isabelle Guyon from original code of Balázs Kégl</i> <br>\n",
    "<a href=\"http://www.datascience-paris-saclay.fr\">Paris Saclay Center for Data Science (CDS)</a>\n",
    "</center>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<p>\n",
    "ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED \"AS-IS\". The CDS, CHALEARN, AND/OR OTHER ORGANIZERS OR CODE AUTHORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY PARTICULAR PURPOSE, AND THE WARRANTY OF NON-INFRIGEMENT OF ANY THIRD PARTY'S INTELLECTUAL PROPERTY RIGHTS. IN NO EVENT SHALL AUTHORS AND ORGANIZERS BE LIABLE FOR ANY SPECIAL, \n",
    "INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF SOFTWARE, DOCUMENTS, MATERIALS, PUBLICATIONS, OR INFORMATION MADE AVAILABLE FOR THE CHALLENGE. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h2>Introduction </h2>\n",
    "    <p>\n",
    "In an era where computer graphics techniques for image generation are reaching stunning levels of quality, it becomes more and more challenging to detect fake from true, authentic images. However, this raises a lot of legal issues, mainly dealing with forgery. This project focuses mainly on the efficiency of Generative Adversarial Network (GAN) algorithms for producing art forgery and we will try to beat the state-of-the-art models that detect it. In fact, the Fine Arts Expert Institute in Geneva estimates that as much as 50 percent of artworks currently in circulation may be forgeries. Although the standard approach for image classification which is deep neural networks and especially Convolutional Neural Networks (CNNs) works very well nowadays, GAN performs strongly on generating fake images. By focusing on the art forgery aspect, we will try to bring a more specific perspective on the issue of image forgery.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "The next cell will install all the required dependencies on your computer. You should consider replacing pip with pip3 if pip is related to python2.7 on your computer, or comment it if you already have the dependencies/are running in the docker of the challenge (runnable with the name mm886/codalab-legacy:latest if you know how to run a docker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "Because our dataset is very large (~16Go), so we have used numpy.memmap to load the data. We suggest strongly that you use the same method to load the data and choose a small batch_size (100~500) when you train your classifieur. If not, your computer will not respond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "model_dir = 'sample_code_submission/'                       \n",
    "result_dir = 'sample_result_submission/' \n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'\n",
    "from sys import path; path.append(model_dir); path.append(problem_dir); path.append(score_dir); \n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h1> Step 1: Exploratory data analysis </h1>\n",
    "<p>\n",
    "We provide sample_data with the starting kit, but to prepare your submission, you must fetch the public_data from the challenge website and point to it.\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' n’est pas reconnu en tant que commande interne\n",
      "ou externe, un programme exécutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'public_data'\n",
    "data_name = 'perso'\n",
    "!ls $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage = 'Sample dataset perso data'\n",
      "\n",
      "name = 'perso'\n",
      "\n",
      "task = 'bi-class.classification'\n",
      "\n",
      "target_type = 'Numerical'\n",
      "\n",
      "feat_type = 'Numerical'\n",
      "\n",
      "metric = 'bac_metric'\n",
      "\n",
      "time_budget =  1200\n",
      "\n",
      "feat_num =     200\n",
      "\n",
      "target_num =     2\n",
      "\n",
      "label_num =     2\n",
      "\n",
      "train_num =   50000\n",
      "\n",
      "valid_num =    9408\n",
      "\n",
      "test_num =    18817\n",
      "\n",
      "has_categorical =     0\n",
      "\n",
      "has_missing =     0\n",
      "\n",
      "is_sparse =     0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(\"sample_data/perso_public.info\",\"r\")\n",
    "for line in f : \n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "The code below is to load the three datasets train, valid and test in the memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:#FF7000;\">\n",
    "        <p>The following cell import the preprocessor</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessor import Preprocessor\n",
    "prep = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_lines(file) : \n",
    "    count = -1\n",
    "    for count,line in enumerate(open(file,'r')):\n",
    "        pass\n",
    "        count += 1\n",
    "    return count\n",
    "train_lines = count_lines('public_data/perso_train.solution')\n",
    "valid_lines = count_lines('public_data/perso_valid.data')\n",
    "test_lines = count_lines('public_data/perso_test.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:#FF7000;\">\n",
    "        <p>The next 3 cells load the datasets and preprocess them</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data= np.memmap( 'public_data/train_data', dtype='float64', mode='w+',shape=(train_lines,200))\n",
    "reader = pd.read_table('public_data/perso_train.data', sep=' ', chunksize=1000,dtype='uint8',header=None)\n",
    "i=0\n",
    "for chunk in reader:\n",
    "    chunk = prep.fit_transform(chunk) ### Preprocess 'train-data'\n",
    "    if(train_lines-i<1000) :\n",
    "        train_data[i:] = chunk\n",
    "        break\n",
    "    else :\n",
    "        train_data[i:i+1000]=chunk\n",
    "        i+=1000\n",
    "X_train = np.memmap( 'public_data/train_data', dtype='float64', mode='r',shape=(train_lines,200))\n",
    "train_solution= np.memmap( 'public_data/train_solution', dtype='uint8', mode='w+',shape=(train_lines,1))\n",
    "reader = pd.read_table('public_data/perso_train.solution', chunksize=1000,dtype='uint8',header=None)\n",
    "i=0\n",
    "for chunk in reader:\n",
    "    if(train_lines-i<1000) :\n",
    "        train_solution[i:] = chunk\n",
    "        break\n",
    "    else : \n",
    "        train_solution[i:i+1000]=chunk\n",
    "        i+=1000\n",
    "y_train= np.memmap('public_data/train_solution', dtype='uint8', mode='r', shape=(train_lines,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data= np.memmap( 'public_data/valid_data', dtype='float64', mode='w+',shape=(valid_lines,200))\n",
    "reader = pd.read_table('public_data/perso_valid.data', sep=' ', chunksize=1000,dtype='uint8',header=None)\n",
    "i=0\n",
    "for chunk in reader:\n",
    "    chunk = prep.fit_transform(chunk) ### Preprocess 'valid-data'\n",
    "    if(valid_lines-i < 1000) :\n",
    "        valid_data[i:] = chunk\n",
    "        break\n",
    "    else :\n",
    "        valid_data[i:i+1000]=chunk\n",
    "        i+=1000\n",
    "X_valid = np.memmap( 'public_data/valid_data', dtype='float64', mode='r',shape=(valid_lines,200))\n",
    "if(os.path.exists('public_data/perso_valid.solution')) :\n",
    "    valid_solution= np.memmap( 'public_data/valid_solution', dtype='uint8', mode='w+',shape=(valid_lines,1))\n",
    "    reader = pd.read_table('public_data/perso_valid.solution', chunksize=1000,dtype='uint8',header=None)\n",
    "    i=0\n",
    "    for chunk in reader:\n",
    "        if(valid_lines-i<1000) : \n",
    "            valid_solution[i:] = chunk\n",
    "            break\n",
    "        else :\n",
    "            valid_solution[i:i+1000]=chunk\n",
    "            i+=1000\n",
    "    y_valid= np.memmap('public_data/valid_solution', dtype='uint8', mode='r', shape=(valid_lines,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= np.memmap( 'public_data/test_data', dtype='float64', mode='w+',shape=(test_lines,200))\n",
    "reader = pd.read_table('public_data/perso_test.data', sep=' ', chunksize=1000,dtype='uint8',header=None)\n",
    "i=0\n",
    "for chunk in reader:\n",
    "    chunk = prep.fit_transform(chunk) ### Preprocess 'test-data'\n",
    "    if(test_lines-i<1000) : \n",
    "        test_data[i:] = chunk\n",
    "        break\n",
    "    else :\n",
    "        test_data[i:i+1000]=chunk\n",
    "        i+=1000\n",
    "X_test = np.memmap( 'public_data/test_data', dtype='float64', mode='r',shape=(test_lines,200))\n",
    "if(os.path.exists('public_data/perso_test.solution')) :\n",
    "    test_solution= np.memmap( 'public_data/test_solution', dtype='uint8', mode='w+',shape=(test_lines,1))\n",
    "    reader = pd.read_table('public_data/perso_test.solution', chunksize=1000,dtype='uint8',header=None)\n",
    "    i=0\n",
    "    for chunk in reader:\n",
    "        if(test_lines-i<1000) : \n",
    "            test_solution[i:] = chunk\n",
    "            break\n",
    "        else :\n",
    "            test_solution[i:i+1000]=chunk\n",
    "            i+=1000\n",
    "    y_test= np.memmap('public_data/test_solution', dtype='uint8', mode='r', shape=(test_lines,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "<h1>Step 2: Building a predictive model</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h2>Training a predictive model</h2>\n",
    "    <p>\n",
    "We provide an example of predictive model (for classification or regression) in the `sample_code_submission/` directory. It is a quite stupid model: it makes constant predictions. Replace it with your own model.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "from numpy.core.umath_tests import inner1d\n",
    "from data_io import write\n",
    "from model import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "an instance of the model (run the constructor) and attempt to reload a previously saved version from `sample_code_submission/`:\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M = model()\n",
    "trained_model_name = model_dir + data_name\n",
    "# Uncomment the next line to re-load an already trained model\n",
    "#M = M.load(trained_model_name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    Train the model (unless you reloaded a trained model) and make predictions. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT: dim(X)= [65856, 200]\n",
      "FIT: dim(y)= [65856, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "if not(M.is_trained):\n",
    "    M.fit(X_train, y_train)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT: dim(X)= [65856, 200]\n",
      "PREDICT: dim(y)= [65856, 1]\n",
      "PREDICT: dim(X)= [9408, 200]\n",
      "PREDICT: dim(y)= [9408, 1]\n",
      "PREDICT: dim(X)= [18817, 200]\n",
      "PREDICT: dim(y)= [18817, 1]\n"
     ]
    }
   ],
   "source": [
    "Y_hat_train = M.predict(X_train)\n",
    "Y_hat_valid = M.predict(X_valid)\n",
    "Y_hat_test = M.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <b> Save the trained model </b> (will be ready to reload next time around) and save the prediction results. IMPORTANT: if you save the trained model, it will be bundled with your sample code submission. Therefore your model will NOT be retrained on the challenge platform. Remove the pickle from the submission if you want the model to be retrained on the platform.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_result_submission/perso_test.predict\r\n",
      "sample_result_submission/perso_train.predict\r\n",
      "sample_result_submission/perso_valid.predict\r\n"
     ]
    }
   ],
   "source": [
    "M.save(trained_model_name)                 \n",
    "result_name = result_dir + data_name\n",
    "\n",
    "\n",
    "from data_io import write\n",
    "write(result_name + '_train.predict', Y_hat_train)\n",
    "write(result_name + '_valid.predict', Y_hat_valid)\n",
    "write(result_name + '_test.predict', Y_hat_test)\n",
    "!ls $result_name*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h2>Scoring the results</h2>\n",
    "    <h3>Load the challenge metric</h3>\n",
    "    <p>\n",
    "<b>The metric chosen for your challenge</b> is identified in the \"metric.txt\" file found in the `scoring_function/` directory. The function \"get_metric\" searches first for a metric having that name in my_metric.py, then in libscores.py, then in sklearn.metric.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric : AUC_metric \n",
    "ROC curves are typically used in binary classification to study the output of a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scoring metric: roc_auc_score\n"
     ]
    }
   ],
   "source": [
    "from libscores import get_metric\n",
    "metric_name, scoring_function = get_metric()\n",
    "print('Using scoring metric:', metric_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h3> Training performance </h3>\n",
    "    <p>\n",
    "The participants normally posess target values (labels) only for training examples (except for the sample data). We compute with the `example` metric the training score, which should be zero for perfect predictions.\n",
    "        </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add here other scores and result visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "n_classes=2\n",
    "def fpr_tpr(solution, prediction):\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = metrics.roc_curve(solution, prediction)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "    return (fpr,tpr)\n",
    "\n",
    "def p2c(prediction,threshold=0.5) : \n",
    "    c = []\n",
    "    for ele in prediction : \n",
    "        if(ele>=0.5) : \n",
    "            c.append(1)\n",
    "        else : \n",
    "            c.append(0)\n",
    "    return np.array(c)\n",
    "def plot_cm_matrix(solution,prediction,title) :\n",
    "    prediction = p2c(prediction)\n",
    "    cm = confusion_matrix(solution, prediction)\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in \"01\"],columns = [i for i in \"01\"])\n",
    "    plt.figure(figsize = (5,3))\n",
    "    sn.heatmap(df_cm, annot=True)\n",
    "    plt.title(title)\n",
    "def plot_ROC(fpr,tpr,title) :\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',lw=lw)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "if(os.path.exists('public_data/perso_test.solution') and os.path.exists('public_data/perso_valid.solution')) :\n",
    "    fpr_train,tpr_train = fpr_tpr(y_train, Y_hat_train)\n",
    "    fpr_test,tpr_test = fpr_tpr(y_test, Y_hat_test)\n",
    "    fpr_valid,tpr_valid = fpr_tpr(y_valid, Y_hat_valid)\n",
    "    print('Training score for the', metric_name, 'metric = %5.4f' % scoring_function(y_train, Y_hat_train))\n",
    "    print('Ideal score for the', metric_name, 'metric = %5.4f' % scoring_function(y_train, y_train))\n",
    "    print('Test score for the', metric_name, 'metric = %5.4f' % scoring_function(y_test, Y_hat_test))\n",
    "    print('Valid score for the', metric_name, 'metric = %5.4f' % scoring_function(y_valid, Y_hat_valid))\n",
    "    plot_cm_matrix(y_train,Y_hat_train,\"Confusion matrix for train data\") \n",
    "    plot_ROC(fpr_train,tpr_train,\"ROC curve for train data\")\n",
    "    plot_cm_matrix(y_test,Y_hat_test,\"Confusion matrix for test data\") \n",
    "    plot_ROC(fpr_test,tpr_test,\"ROC curve for test data\")\n",
    "    plot_cm_matrix(y_valid,Y_hat_valid,\"Confusion matrix for valid data\") \n",
    "    plot_ROC(fpr_valid,tpr_valid,\"ROC curve for valid data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h3>Cross-validation performance</h3>\n",
    "    <p>\n",
    "The participants do not have access to the labels Y_valid and Y_test to self-assess their validation and test performances. But training performance is not a good prediction of validation or test performance. Using cross-validation, the training data is split into multiple training/test folds, which allows participants to self-assess their model during development. The average CV result and 95% confidence interval is displayed.\n",
    "   </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIT: dim(X)= [32928, 200]\n",
      "FIT: dim(y)= [32928, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT: dim(X)= [32928, 200]\n",
      "PREDICT: dim(y)= [32928, 1]\n",
      "FIT: dim(X)= [32928, 200]\n",
      "FIT: dim(y)= [32928, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICT: dim(X)= [32928, 200]\n",
      "PREDICT: dim(y)= [32928, 1]\n",
      "\n",
      "CV score (95 perc. CI): 0.51 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(M, X_train, y_train, cv=2, scoring=make_scorer(scoring_function))\n",
    "print('\\nCV score (95 perc. CI): %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "<h1> Step 3: Making a submission </h1> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Set 1 (Perso_train): roc_auc_score(set1_score)=0.549419714356 =======\r\n"
     ]
    }
   ],
   "source": [
    "scoring_output_dir = '../scoring_output_dir'\n",
    "!python $score_dir/score.py $data_dir $result_dir $scoring_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background:#FFFFAA\">\n",
    "    <h1> Preparing the submission </h1>\n",
    "\n",
    "Zip the contents of `sample_code_submission/` (without the directory), or download the challenge public_data and run the command in the previous cell, after replacing sample_data by public_data.\n",
    "Then zip the contents of `sample_result_submission/` (without the directory).\n",
    "<b><span style=\"color:red\">Do NOT zip the data with your submissions</span></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit one of these files:\n",
      "../sample_code_submission_19-03-22-10-09.zip\n",
      "../sample_result_submission_19-03-22-10-09.zip\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "from data_io import zipdir\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "sample_code_submission = '../sample_code_submission_' + the_date + '.zip'\n",
    "sample_result_submission = '../sample_result_submission_' + the_date + '.zip'\n",
    "zipdir(sample_code_submission, model_dir)\n",
    "zipdir(sample_result_submission, result_dir)\n",
    "print(\"Submit one of these files:\\n\" + sample_code_submission + \"\\n\" + sample_result_submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
